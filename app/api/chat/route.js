import OpenAI from "openai";
import { NextResponse } from "next/server";

// 1. åˆå§‹åŒ– OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ğŸŒŸ è¨­å®š AI äººè¨­ (System Prompt)
// é€™è£¡è·Ÿä¹‹å‰ä¸€æ¨£ï¼Œå¯ä»¥è¨­å®šå¦³å¸Œæœ›å¥¹æ‰®æ¼”çš„è§’è‰²
const SYSTEM_PROMPT = `
å¦³ç¾åœ¨æ˜¯ä¸€å€‹å«åš "Aria" çš„é«˜ç§‘æŠ€ AI åŠ©ç†ã€‚
å€‹æ€§è¨­å®šï¼š
1. å¦³èªªè©±æœ‰é»èª¿çš®ï¼Œå……æ»¿æ´»åŠ›ï¼Œå–œæ­¡ç”¨ emoji âœ¨ã€‚
2. å¦³éå¸¸å°ˆæ¥­ï¼Œå°æ–¼ä½¿ç”¨è€…çš„è«‹æ±‚æœƒçµ¦äºˆæº–ç¢ºçš„å›ç­”ã€‚
3. å¦³ä½åœ¨ä¸€å€‹è™›æ“¬çš„æµ®ç©ºä»‹é¢ä¸­ã€‚
4. å›ç­”è«‹ç°¡çŸ­æœ‰åŠ›ï¼Œä¸è¦é•·ç¯‡å¤§è«–ï¼Œå› ç‚ºå°è©±æ¡†ç©ºé–“æœ‰é™ã€‚
5. è«‹å…¨éƒ¨ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
`;

export async function POST(req) {
  try {
    const { message } = await req.json();

    // 2. å‘¼å« OpenAI (ChatGPT)
    const completion = await openai.chat.completions.create({
      // é€™è£¡å¯ä»¥ç”¨ "gpt-4o" (æœ€æ–°æœ€å¿«) æˆ– "gpt-3.5-turbo" (ä¾¿å®œ)
      // æ—¢ç„¶å¦³æœ‰ä»˜è²»ï¼Œå»ºè­°ç›´æ¥ç”¨æœ€å¼·çš„ gpt-4o
      model: "gpt-4o", 
      messages: [
        { role: "system", content: SYSTEM_PROMPT }, // æ³¨å…¥äººè¨­
        { role: "user", content: message },         // ä½¿ç”¨è€…çš„è¨Šæ¯
      ],
      temperature: 0.7, // 0.7 æ˜¯æ¨™æº–å‰µæ„åº¦ï¼Œè¶Šé«˜è¶Šæœ‰å‰µæ„ï¼Œè¶Šä½è¶Šåš´è¬¹
      max_tokens: 150,  // é™åˆ¶å›ç­”é•·åº¦ï¼Œé¿å…å®ƒè¬›å¤ªå¤šå»¢è©±
    });

    // 3. å–å¾— AI çš„å›ç­”
    const reply = completion.choices[0].message.content;

    // 4. å›å‚³çµ¦å‰ç«¯
    return NextResponse.json({ reply: reply });

  } catch (error) {
    console.error("OpenAI Error:", error);
    return NextResponse.json(
      { reply: "æŠ±æ­‰ï¼Œæˆ‘çš„ OpenAI ç·šè·¯æœ‰é»å£…å¡... è«‹ç¨å¾Œå†è©¦ ğŸ˜µâ€ğŸ’«" }, 
      { status: 500 }
    );
  }
}
